

<!DOCTYPE html>


<html lang="ja" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<meta property="og:title" content="画像生成 AI 入門: Python による拡散モデルの理論と実践" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://shunk031.me/coloso-python-diffusion-models/lectures/section-07-23.html" />
<meta property="og:site_name" content="画像生成AI入門: Pythonによる拡散モデルの理論と実践" />
<meta property="og:description" content="Open In Colab Section 07. Play with Diffusion Model: Stable Diffusion を中心とした拡散モデルを用いて、最先端の画像生成技術を実際に動かして実践していきます。 Lecture 23. ControlNet: ControlNet[Zhang+ CoRR'23] を用いて Stable Diffusion 等の生成モデルが苦手..." />
<meta property="og:image" content="https://raw.githubusercontent.com/shunk031/coloso-python-diffusion-models/main/assets/logo.png" />
<meta property="og:image:alt" content="画像生成AI入門: Pythonによる拡散モデルの理論と実践" />
<meta name="description" content="Open In Colab Section 07. Play with Diffusion Model: Stable Diffusion を中心とした拡散モデルを用いて、最先端の画像生成技術を実際に動かして実践していきます。 Lecture 23. ControlNet: ControlNet[Zhang+ CoRR'23] を用いて Stable Diffusion 等の生成モデルが苦手..." />

    <title>画像生成 AI 入門: Python による拡散モデルの理論と実践 &#8212; 画像生成AI入門: Pythonによる拡散モデルの理論と実践</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-8ZY8TGCYMR"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-8ZY8TGCYMR');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/section-07-23';</script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="検索" href="../search.html" />
    <link rel="next" title="画像生成 AI 入門: Python による拡散モデルの理論と実践" href="section-07-24.html" />
    <link rel="prev" title="画像生成 AI 入門: Python による拡散モデルの理論と実践" href="section-07-22.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ja"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    画像生成 AI 入門：Python による拡散モデルの理論と実践
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-01-03.html">Play with Stable Diffusion!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-02-05.html">About Deep Learning (2)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-03-08.html">Score-based Generative Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-03-09.html">Denoising Diffusion Probabilistic Model (1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-03-10.html">Denoising Diffusion Probabilistic Model (2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-03-11.html">Beyond Conventional GANs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-04-12.html">About CLIP</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-06-18.html">Components of Stable Diffusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 7</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-07-19.html">Stable Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-20.html">Textual Inversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-21.html">DreamBooth</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-22.html">Attend-and-Excite</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">ControlNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-24.html">Prompt-to-Prompt</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-25.html">InstructPix2Pix</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-26.html">unCLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-27.html">Paint-by-example</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-28.html">LoRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-29.html">Safe Latent Diffusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">受講者特典</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../materials/figures/README.html">高解像度図表</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/shunk031/coloso-python-diffusion-models/blob/main/lectures/section-07-23.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/shunk031/coloso-python-diffusion-models" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="ソースリポジトリ"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/shunk031/coloso-python-diffusion-models/issues/new?title=Issue%20on%20page%20%2Flectures/section-07-23.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="問題を報告"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="このページをダウンロード">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/section-07-23.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="ソースファイルをダウンロード"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="PDFに印刷"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="全画面モード"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="検索" aria-label="検索" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>画像生成 AI 入門: Python による拡散モデルの理論と実践</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> 目次 </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-07-play-with-diffusion-model">Section 07. Play with Diffusion Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-23-controlnet">Lecture 23. ControlNet</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">セットアップ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu">GPU が使用できるか確認</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#python">利用する Python ライブラリをインストール</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlnet">ControlNet を扱うパイプラインを構築</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny">Canny エッジ画像の作成</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny-controlnet">Canny エッジ画像を用いた ControlNet による画像生成</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#controlnet-dreambooth">ControlNet と DreamBooth の組み合わせ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">姿勢情報を用いた ControlNet による画像生成</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">ControlNet による複数の条件を組み合わせた画像生成</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Canny エッジ画像の取得</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">姿勢情報の取得</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">複数の条件による ControlNet を動かす</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ai-python">
<h1>画像生成 AI 入門: Python による拡散モデルの理論と実践<a class="headerlink" href="#ai-python" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/shunk031/coloso-python-diffusion-models/blob/main/lectures/section-07-23.ipynb" rel="noreferrer" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section id="section-07-play-with-diffusion-model">
<h2>Section 07. Play with Diffusion Model<a class="headerlink" href="#section-07-play-with-diffusion-model" title="Permalink to this heading">#</a></h2>
<p>Stable Diffusion を中心とした拡散モデルを用いて、最先端の画像生成技術を実際に動かして実践していきます。</p>
<section id="lecture-23-controlnet">
<h3>Lecture 23. ControlNet<a class="headerlink" href="#lecture-23-controlnet" title="Permalink to this heading">#</a></h3>
<p>ControlNet <a class="reference external" href="https://arxiv.org/abs/2302.05543" rel="noreferrer" target="_blank">[Zhang+ CoRR'23]</a> を用いて Stable Diffusion 等の生成モデルが苦手としている、意図したスタイルや構図の反映を忠実に行う画像生成を実現します。</p>
</section>
</section>
<section id="id1">
<h2>セットアップ<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<section id="gpu">
<h3>GPU が使用できるか確認<a class="headerlink" href="#gpu" title="Permalink to this heading">#</a></h3>
<p>本 Colab ノートブックを実行するために GPU ランタイムを使用していることを確認します。CPU ランタイムと比べて画像生成がより早くなります。以下の <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> コマンドが失敗する場合は再度講義資料の <code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">使用設定</span></code> のスライド説明や Google Colab の <a class="reference external" href="https://research.google.com/colaboratory/faq.html#gpu-utilization" rel="noreferrer" target="_blank">FAQ</a> 等を参考にランタイムタイプが正しく変更されているか確認してください。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tue Jul 18 13:44:09 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   37C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
</section>
<section id="python">
<h3>利用する Python ライブラリをインストール<a class="headerlink" href="#python" title="Permalink to this heading">#</a></h3>
<p>diffusers ライブラリをインストールすることで拡散モデルを簡単に使用できるようにします。diffusers ライブラリを動かす上で必要となるライブラリも追加でインストールします:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/huggingface/transformers" rel="noreferrer" target="_blank">transformers</a>: 拡散モデルにおいて核となる Transformer モデルが定義されているライブラリ</p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/accelerate" rel="noreferrer" target="_blank">accelerate</a>: transformers と連携してより高速な画像生成をサポートするライブラリ</p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/xformers" rel="noreferrer" target="_blank">xformers</a>: accelerate と同様に、Transformer モデルをより効率的に扱い高速な画像生成をサポートするライブラリ</p></li>
</ul>
<p>入力する条件によって、画像に対して異なる前処理が必要になるため、以下に画像処理用のライブラリを追加でインストールします:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/opencv/opencv-python" rel="noreferrer" target="_blank">opencv-contrib-python</a>: 画像処理ライブラリ OpenCV の python 向けライブラリ</p></li>
<li><p><a class="reference external" href="https://github.com/patrickvonplaten/controlnet_aux" rel="noreferrer" target="_blank">controlnet-aux</a>: ControlNet の前処理モデルが集まったライブラリ</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">diffusers</span><span class="o">==</span><span class="m">0</span>.16.1
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>accelerate<span class="w"> </span>xformers
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>opencv-contrib-python<span class="w"> </span>controlnet_aux
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: diffusers==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (8.4.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (3.12.2)
Requirement already satisfied: huggingface-hub&gt;=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (0.16.4)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (6.8.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (1.22.4)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (2022.10.31)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (2.27.1)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (2023.6.0)
Requirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (4.65.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (6.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (4.7.1)
Requirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (23.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata-&gt;diffusers==0.16.1) (3.16.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (3.4)
Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)
Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.21.0)
Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.20)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)
Requirement already satisfied: safetensors&gt;=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)
Requirement already satisfied: torch&gt;=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)
Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.10/dist-packages (from xformers) (0.0.29)
Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29-&gt;xformers) (0.9.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29-&gt;xformers) (4.7.1)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.10.0-&gt;accelerate) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.10.0-&gt;accelerate) (16.0.6)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (2023.6.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=1.10.0-&gt;accelerate) (2.1.3)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=1.10.0-&gt;accelerate) (1.3.0)
Requirement already satisfied: mypy-extensions&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect-&gt;pyre-extensions==0.0.29-&gt;xformers) (1.0.0)
Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)
Requirement already satisfied: controlnet_aux in /usr/local/lib/python3.10/dist-packages (0.0.6)
Requirement already satisfied: numpy&gt;=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.22.4)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (8.4.0)
Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (0.6.1)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (3.12.2)
Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (0.16.4)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (6.8.0)
Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (4.7.0.72)
Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (0.19.3)
Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (1.10.1)
Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (0.9.2)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (2.0.1+cu118)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from controlnet_aux) (0.15.2+cu118)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;controlnet_aux) (2023.6.0)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;controlnet_aux) (2.27.1)
Requirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;controlnet_aux) (4.65.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;controlnet_aux) (6.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;controlnet_aux) (4.7.1)
Requirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;controlnet_aux) (23.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata-&gt;controlnet_aux) (3.16.1)
Requirement already satisfied: networkx&gt;=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image-&gt;controlnet_aux) (3.1)
Requirement already satisfied: imageio&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image-&gt;controlnet_aux) (2.25.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image-&gt;controlnet_aux) (2023.7.10)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image-&gt;controlnet_aux) (1.4.1)
Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm-&gt;controlnet_aux) (0.3.1)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;controlnet_aux) (1.11.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;controlnet_aux) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;controlnet_aux) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;controlnet_aux) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;controlnet_aux) (16.0.6)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;controlnet_aux) (2.1.3)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;controlnet_aux) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;controlnet_aux) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;controlnet_aux) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;controlnet_aux) (3.4)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;controlnet_aux) (1.3.0)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="controlnet">
<h2>ControlNet を扱うパイプラインを構築<a class="headerlink" href="#controlnet" title="Permalink to this heading">#</a></h2>
<p>本セクションでは <a class="reference external" href="https://huggingface.co/docs/diffusers/v0.16.0/en/api/pipelines/stable_diffusion/controlnet#diffusers.StableDiffusionControlNetPipeline" rel="noreferrer" target="_blank"><code class="docutils literal notranslate"><span class="pre">StableDiffusionControlNetPipeline</span></code></a> を使用して ControlNet パイプラインの動作を確認します。</p>
<p>以下、<a class="reference external" href="https://huggingface.co/blog/controlnet" rel="noreferrer" target="_blank">ControlNet in 🧨 Diffusers</a> を参考に動作を追っていきます。まず始めに扱う ControlNet は、<code class="docutils literal notranslate"><span class="pre">Canny</span> <span class="pre">model</span></code> と呼ばれる canny edge 法を用いたエッジ検出をした画像を元に生成画像の構図を制御するモデルを使用します。</p>
<p>まず準備として画像を複数生成した場合に結果を確認しやすいように、画像をグリッド上に表示する関数を以下のように定義します。この関数は <a class="reference external" href="https://huggingface.co/blog/stable_diffusion" rel="noreferrer" target="_blank">🤗 Hugging Face Stable Diffusion</a> のブログ記事のものを利用しています。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">PIL.Image</span> <span class="kn">import</span> <span class="n">Image</span> <span class="k">as</span> <span class="n">PilImage</span>

<span class="k">def</span> <span class="nf">image_grid</span><span class="p">(</span><span class="n">imgs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PilImage</span><span class="p">],</span> <span class="n">rows</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">cols</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PilImage</span><span class="p">:</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span> <span class="o">==</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span>

    <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">cols</span> <span class="o">*</span> <span class="n">w</span><span class="p">,</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">h</span><span class="p">))</span>
    <span class="n">grid_w</span><span class="p">,</span> <span class="n">grid_h</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">size</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">imgs</span><span class="p">):</span>
        <span class="n">grid</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">box</span><span class="o">=</span><span class="p">(</span><span class="n">i</span><span class="o">%</span><span class="k">cols</span>*w, i//cols*h))
    <span class="k">return</span> <span class="n">grid</span>
</pre></div>
</div>
</div>
</div>
<p>今回はフェルメールの有名な絵画「真珠の少女」を使用します。以下のようにして画像をダウンロードします。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">diffusers.utils</span> <span class="kn">import</span> <span class="n">load_image</span>

<span class="n">image_pil</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span><span class="s2">&quot;https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png&quot;</span><span class="p">)</span>
<span class="n">image_pil</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/22a917b48d85467516de1cbb783a1ace299a6aa320d11ac6a0d4144ab0694978.png" src="../_images/22a917b48d85467516de1cbb783a1ace299a6aa320d11ac6a0d4144ab0694978.png" />
</div>
</div>
<section id="canny">
<h3>Canny エッジ画像の作成<a class="headerlink" href="#canny" title="Permalink to this heading">#</a></h3>
<p>読み込んだ画像に対して Canny エッジ検出を適用します。実行結果を確認すると入力画像から十分なエッジが検出されています。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">canny_preprocessor</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">PilImage</span><span class="p">,</span> <span class="n">low_threshold</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">high_threshold</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PilImage</span><span class="p">:</span>
    <span class="n">image_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="n">image_arr</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">image_arr</span><span class="p">,</span> <span class="n">low_threshold</span><span class="p">,</span> <span class="n">high_threshold</span><span class="p">)</span>
    <span class="n">image_arr</span> <span class="o">=</span> <span class="n">image_arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">image_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">image_arr</span><span class="p">,</span> <span class="n">image_arr</span><span class="p">,</span> <span class="n">image_arr</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">canny_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image_arr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">canny_image</span>

<span class="n">canny_image</span> <span class="o">=</span> <span class="n">canny_preprocessor</span><span class="p">(</span><span class="n">image_pil</span><span class="p">,</span> <span class="n">low_threshold</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">high_threshold</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">canny_image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0890ffb2e83c1884ca81b10b5c394d2a1e09caabe9f09708cc98955e47f49546.png" src="../_images/0890ffb2e83c1884ca81b10b5c394d2a1e09caabe9f09708cc98955e47f49546.png" />
</div>
</div>
</section>
<section id="canny-controlnet">
<h3>Canny エッジ画像を用いた ControlNet による画像生成<a class="headerlink" href="#canny-controlnet" title="Permalink to this heading">#</a></h3>
<p>Canny エッジ検出に対応する ControlNet として <code class="docutils literal notranslate"><span class="pre">lllyasviel/sd-controlnet-canny</span></code> を読み込み、更に Stable Diffusion として <code class="docutils literal notranslate"><span class="pre">runwayml/stable-diffusion-v1-5</span></code> を読み込みます。このとき <code class="docutils literal notranslate"><span class="pre">StableDiffusionControlNetPipeline</span></code> を使用して、読み込んだ ControlNet をパイプラインに渡します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">diffusers</span> <span class="kn">import</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="p">,</span> <span class="n">ControlNetModel</span>

<span class="n">controlnet_model_id</span> <span class="o">=</span> <span class="s2">&quot;lllyasviel/sd-controlnet-canny&quot;</span>
<span class="n">controlnet</span> <span class="o">=</span> <span class="n">ControlNetModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">controlnet_model_id</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>

<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_id</span><span class="p">,</span> <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnet</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[&quot;id2label&quot;]` will be overriden.
</pre></div>
</div>
</div>
</div>
<p>Stable Diffusion のデフォルトのノイズスケジューラである <a class="reference external" href="https://huggingface.co/docs/diffusers/main/en/api/schedulers/pndm" rel="noreferrer" target="_blank"><code class="docutils literal notranslate"><span class="pre">PNDMScheduler</span></code></a> を使うかわりに、<a class="reference external" href="https://huggingface.co/docs/diffusers/api/schedulers/unipc" rel="noreferrer" target="_blank"><code class="docutils literal notranslate"><span class="pre">UniPCMultistepScheduler</span></code></a> という現在最速のスケジューラを使用してみます。改良されたスケジューラを利用することで、推論時間を劇的に短縮することができます。今回のケースでは、画像生成の品質はそのままに、推論時のステップ数をデフォルトの 50 から 20 に減らすことができました。スケジューラに関する詳しい情報は <a class="reference external" href="https://huggingface.co/docs/diffusers/main/en/using-diffusers/schedulers" rel="noreferrer" target="_blank">こちら</a> から確認できます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">diffusers</span> <span class="kn">import</span> <span class="n">UniPCMultistepScheduler</span>

<span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">UniPCMultistepScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>パイプラインを <code class="docutils literal notranslate"><span class="pre">.to(&quot;cuda&quot;)</span></code> 等で GPU に直接移動するかわりに、<code class="docutils literal notranslate"><span class="pre">enable_model_cpu_offload</span></code> 関数を呼び出すことで、必要なタイミングで必要な層が GPU 上で動作する CPU offload 機能が有効になります。</p>
<p>Stable Diffusion のような拡散モデルは、推論時に複数のコンポーネントを使用して、それらが順次実行されます。ControlNet を用いた Stable Diffusion の場合、以下の工程があります:</p>
<ul class="simple">
<li><p>CLIP テキストエンコーダの使用</p></li>
<li><p>U-Net と ControlNet の使用</p></li>
<li><p>VAE デコーダの使用</p></li>
<li><p>NSFW (Not safe for work) 画像に対する safety checker に使用</p></li>
</ul>
<p>ほとんどのコンポーネントは拡散過程中に一度だけ実行されるため、GPU メモリを常に専有する必要はありません。<code class="docutils literal notranslate"><span class="pre">enable_model_cpu_offload</span></code> を使用することで、各コンポーネントが必要なときだけ GPU に読み込まれるようにし、推論速度を減速させること無く、メモリ消費を大幅に抑えることができます。</p>
<p>ここで注意ですが、<code class="docutils literal notranslate"><span class="pre">enable_model_cpu_offload</span></code> を実行するときは、<code class="docutils literal notranslate"><span class="pre">.to(&quot;cuda&quot;)</span></code> を使って手動でパイプラインを GPU に移動させないでください。CPU offload が有効になると、パイプラインは自動的に GPU への移動を行います。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">enable_model_cpu_offload</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>更に、<a class="reference external" href="https://github.com/facebookresearch/xformers" rel="noreferrer" target="_blank"><code class="docutils literal notranslate"><span class="pre">xformers</span></code> に実装されている <code class="docutils literal notranslate"><span class="pre">Flash</span> <span class="pre">Attention</span></code></a> を有効にします。Flash Attention を用いることで GPU RAM の削減や推論速度の向上が期待できます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">enable_xformers_memory_efficient_attention</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>これで ControlNet を組み込んだ Stable Diffusion パイプラインを実行する準備が整いました。</p>
<p>通常の Stable Diffusion による image-to-image 画像生成と同じようにプロンプトをパイプラインに入力します。しかしながら ControlNet では生成される画像をよりコントロール可能になります。これは Canny エッジ画像を元に、生成される画像の正確な構図をコントールできるからです。</p>
<p>女優や歌手を含む現代の有名人である <code class="docutils literal notranslate"><span class="pre">サンドラ・オー</span></code> (Sandra Oh)、<code class="docutils literal notranslate"><span class="pre">キム・カーダシアン</span></code> (Kim Kardashian)、<code class="docutils literal notranslate"><span class="pre">リアーナ</span></code> (rihanna)、<code class="docutils literal notranslate"><span class="pre">テイラー・スウィフト</span></code> (taylor swift) が、17 世紀に描かれた絵と全く同じポーズをとっている画像を見るのは非常に興味深いと思います。これを実現するためには、単にプロンプトにその有名人の名前を入れるだけで達成できます！</p>
<p>入力するプロンプトを定義して、再現性のための乱数の seed を設定します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">modification_prompt</span> <span class="o">=</span> <span class="s2">&quot;, best quality, extremely detailed&quot;</span>
<span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Sandra Oh&quot;</span><span class="p">,</span> <span class="s2">&quot;Kim Kardashian&quot;</span><span class="p">,</span> <span class="s2">&quot;rihanna&quot;</span><span class="p">,</span> <span class="s2">&quot;taylor swift&quot;</span><span class="p">]</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">19950815</span>

<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">target</span> <span class="o">+</span> <span class="n">modification_prompt</span> <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">]</span>
<span class="n">generator</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">))]</span>
</pre></div>
</div>
</div>
</div>
<p>上記の設定を元に、パイプラインを実行して生成画像を表示してみます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">negative_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;monochrome, lowres, bad anatomy, worst quality, low quality&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="n">prompts</span><span class="p">,</span>
    <span class="n">image</span><span class="o">=</span><span class="n">canny_image</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>

<span class="p">)</span><span class="o">.</span><span class="n">images</span>

<span class="n">image_grid</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output hidden; open in https://colab.research.google.com to view.
</pre></div>
</div>
</div>
</div>
</section>
<section id="controlnet-dreambooth">
<h3>ControlNet と DreamBooth の組み合わせ<a class="headerlink" href="#controlnet-dreambooth" title="Permalink to this heading">#</a></h3>
<p>ControlNet と fine-tuning 技術は簡単に組み合わせることができます。たとえば
<a class="reference external" href="https://arxiv.org/abs/2208.12242" rel="noreferrer" target="_blank">DreamBooth</a> でモデルを fine-tuning し、それを使って自分自身を様々なシーンに描画することができます。</p>
<p>今回は Mr. ポテトヘッドを例に、ControlNet と DreamBooth の使い方を紹介します。これまでと同様の ControlNet を使用できますが、Stable Diffusion v1.5 を使用するかわりに DreamBooth で fine-tuning した <code class="docutils literal notranslate"><span class="pre">sd-dreambooth-library/mr-potato-head</span></code> を利用します。</p>
<p>ここで Colab のメモリ容量を気にして、これまで使用したパイプライン <code class="docutils literal notranslate"><span class="pre">pipe</span></code> を削除し、<code class="docutils literal notranslate"><span class="pre">sd-dreambooth-library/mr-potato-head</span></code> を読み込みます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gc</span>

<span class="k">del</span> <span class="n">pipe</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>300
</pre></div>
</div>
</div>
</div>
<p>次に MR. ポテトヘッドを dreambooth で学習させた <code class="docutils literal notranslate"><span class="pre">sd-dreambooth-library/mr-potato-head</span></code> を読み込ませます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;sd-dreambooth-library/mr-potato-head&quot;</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_id</span><span class="p">,</span> <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnet</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">UniPCMultistepScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

<span class="n">pipe</span><span class="o">.</span><span class="n">enable_model_cpu_offload</span><span class="p">()</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">enable_xformers_memory_efficient_attention</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "1087aef4409a4ae5ab49840196da08ad"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>vae/diffusion_pytorch_model.safetensors not found
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "1abab8e55a4b4e6b87551c40fd45fd74"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "38388b78bdac4215927e336f053cc3b3"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "61435dcc17e043f7a418a100abbdee8d"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "8bcee24a3e7348dc8885e3564af69cb2"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "a7081cbf22fd484da6f23c397bab04da"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "20926c8471fe4ded81fc10ec7d99f04d"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "64916a7d43ae4aeb9c27315253c1335d"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "46e74c097fa34d78a2fc9f35638673f9"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "28b96eafcffd414ca4b90b465f716f2e"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b439a3443a594c3fa90ae2fcfacfc1dd"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "620bd25de5bd43a495e6841d64f30f5b"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "c417726eed08488d95a8f6364716db58"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "9892d5f96dc34edbae6f0cb24db7b58a"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "3f98f7e114d5419383c4e19c17799eda"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "77a9b49e63394864a4cd96f31cbd56f7"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[&quot;id2label&quot;]` will be overriden.
</pre></div>
</div>
</div>
</div>
<p>では、フェルメールの絵画と同じポーズを取る Mr. ポテトヘッドを生成してみましょう！</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;a photo of sks mr potato head, best quality, extremely detailed&quot;</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">,</span>
    <span class="n">image</span><span class="o">=</span><span class="n">canny_image</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="o">=</span><span class="s2">&quot;monochrome, lowres, bad anatomy, worst quality, low quality&quot;</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "cd906d51c75c4316af73111bf9c9144d"}</script><img alt="../_images/af5d7996adb54ba96d2c62a98c1a702e2e0200af502ff51b3a020bbb691b6c44.png" src="../_images/af5d7996adb54ba96d2c62a98c1a702e2e0200af502ff51b3a020bbb691b6c44.png" />
</div>
</div>
<p>Mr. ポテトヘッドにフェルメールの絵画のポーズを取らせるのはもしかしたら適切ではないかもしれませんが、&quot;彼&quot; はベストを尽くしてフェルメールの絵画になりきってくれています🍟</p>
<p>再度、Colab RAM の節約のために上記で使用したパイプライン <code class="docutils literal notranslate"><span class="pre">pipe</span></code> を削除します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gc</span>

<span class="k">del</span> <span class="n">pipe</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>52
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>姿勢情報を用いた ControlNet による画像生成<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>ControlNet は Canny エッジ画像にとどまらず、さまざまな情報による生成画像の制御が可能です。ここでは、ある画像から姿勢情報を取り出し、それを再利用して全く同じポーズの別の画像を生成する方法を紹介します。ここでは Open Pose ControlNet を使って、スーパーヒーローにヨガのやり方を教えてみましょう！</p>
<p>まずはヨガをしている画像をいくつか用意します:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">urls</span> <span class="o">=</span> <span class="s2">&quot;yoga1.jpeg&quot;</span><span class="p">,</span> <span class="s2">&quot;yoga2.jpeg&quot;</span><span class="p">,</span> <span class="s2">&quot;yoga3.jpeg&quot;</span><span class="p">,</span> <span class="s2">&quot;yoga4.jpeg&quot;</span>
<span class="n">imgs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">load_image</span><span class="p">(</span><span class="s2">&quot;https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/&quot;</span> <span class="o">+</span> <span class="n">url</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span>
<span class="p">]</span>

<span class="n">image_grid</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9f957508d30cc50cc2d1bba5faa69983278d95e33da2602e038bdcef6ba3da18.png" src="../_images/9f957508d30cc50cc2d1bba5faa69983278d95e33da2602e038bdcef6ba3da18.png" />
</div>
</div>
<p>次に <code class="docutils literal notranslate"><span class="pre">controlnet_aux</span></code> 経由で簡単に利用できる <code class="docutils literal notranslate"><span class="pre">OpenPoseDetector</span></code> を使用して、ヨガの姿勢情報を抽出してみましょう。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">controlnet_aux</span> <span class="kn">import</span> <span class="n">OpenposeDetector</span>

<span class="n">openpose</span> <span class="o">=</span> <span class="n">OpenposeDetector</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;lllyasviel/ControlNet&quot;</span><span class="p">)</span>

<span class="n">poses</span> <span class="o">=</span> <span class="p">[</span><span class="n">openpose</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">imgs</span><span class="p">]</span>
<span class="n">image_grid</span><span class="p">(</span><span class="n">poses</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module &#39;mediapipe&#39; is not installed. The package will have limited functionality. Please install it using the command: pip install &#39;mediapipe&#39;
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/ccb4c641898f27ca000ffdeac436c81098f79394fd7318ed0744dc547de56298.png" src="../_images/ccb4c641898f27ca000ffdeac436c81098f79394fd7318ed0744dc547de56298.png" />
</div>
</div>
<p>姿勢情報を扱えるように事前学習された ControlNet を読み込むにあたって、これまで使っていた Canny エッジ用 ControlNet は削除し、Colab の RAM を節約します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">controlnet</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>24105
</pre></div>
</div>
</div>
</div>
<p>上記で用意したヨガのポーズ情報を使って新しい画像を生成するために、Open Pose ControlNet を読み込んでみましょう。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">controlnet_model_id</span> <span class="o">=</span> <span class="s2">&quot;fusing/stable-diffusion-v1-5-controlnet-openpose&quot;</span>
<span class="n">controlnet</span> <span class="o">=</span> <span class="n">ControlNetModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">controlnet_model_id</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>

<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_id</span><span class="p">,</span>
    <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnet</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">UniPCMultistepScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">enable_model_cpu_offload</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "64d64f8f61d140f99dfec9e85d2d4252"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "fab2fae57fe946f394061ed576c14c5d"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[&quot;id2label&quot;]` will be overriden.
</pre></div>
</div>
</div>
</div>
<p>では、以下を実行してヨガのポーズを取るヒーローの画像を生成させてみましょう🚀 Now it's yoga time!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nrows</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ncols</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">num_images</span> <span class="o">=</span> <span class="n">nrows</span> <span class="o">*</span> <span class="n">ncols</span>

<span class="n">generator</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span><span class="p">)]</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;super-hero character, best quality, extremely detailed&quot;</span>
<span class="n">negative_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;monochrome, lowres, bad anatomy, worst quality, low quality&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="p">[</span><span class="n">prompt</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span><span class="p">,</span>
    <span class="n">poses</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">images</span>
<span class="n">image_grid</span><span class="p">(</span><span class="n">images</span> <span class="o">+</span> <span class="n">poses</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output hidden; open in https://colab.research.google.com to view.
</pre></div>
</div>
</div>
</div>
<p>使用したパイプラインと ControlNet を削除しておきます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">pipe</span><span class="p">;</span> <span class="k">del</span> <span class="n">controlnet</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>584
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id3">
<h2>ControlNet による複数の条件を組み合わせた画像生成<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<p>ControlNet は Canny エッジや姿勢情報単体でも素晴らしい制御能力を発揮しますが、これらを複数組み合わせることも可能です。</p>
<p>条件付けを複数組み合わせるときは、条件どうしが重ならないようにマスクするとより良い生成結果を得やすくなります。今回の例では、姿勢情報の条件がある中央部分に対して、Canny エッジ画像をマスクします。</p>
<p>また <code class="docutils literal notranslate"><span class="pre">controlnet_conditioning_scales</span></code> というパラメータを変化させることで、それぞれの条件を重み付けすることができます。</p>
<section id="id4">
<h3>Canny エッジ画像の取得<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>まずは Canny エッジ画像を用いた条件付けの準備をします。以下のようにして元となる画像をダウンロードしてきます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_pil</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span><span class="s2">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png&quot;</span><span class="p">)</span>
<span class="n">image_pil</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/623f1fcad62ea56a4b0c1a89469af8c467b53931d9a5208acf188992a273a4fc.png" src="../_images/623f1fcad62ea56a4b0c1a89469af8c467b53931d9a5208acf188992a273a4fc.png" />
</div>
</div>
<p>Canny エッジ画像を生成します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">canny_image</span> <span class="o">=</span> <span class="n">canny_preprocessor</span><span class="p">(</span><span class="n">image_pil</span><span class="p">,</span> <span class="n">low_threshold</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">high_threshold</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>人物姿勢情報を合成するため、中央部分はゼロ埋めしておきます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">canny_image</span><span class="p">)</span>
<span class="n">zero_start</span> <span class="o">=</span> <span class="n">image_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span>
<span class="n">zero_end</span> <span class="o">=</span> <span class="n">zero_start</span> <span class="o">+</span> <span class="n">image_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
<span class="n">image_arr</span><span class="p">[:,</span> <span class="n">zero_start</span><span class="p">:</span><span class="n">zero_end</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">canny_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image_arr</span><span class="p">)</span>
<span class="n">canny_image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/602d90fc54f4c31cf442c42d6a18935dcf2130d932eee3f1e3205d5a60eb1496.png" src="../_images/602d90fc54f4c31cf442c42d6a18935dcf2130d932eee3f1e3205d5a60eb1496.png" />
</div>
</div>
</section>
<section id="id5">
<h3>姿勢情報の取得<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>次に Open Pose を用いた姿勢情報による条件付けの準備をします。以下のようにして対象となる画像をダウンロードします。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">original_image</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span><span class="s2">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/person.png&quot;</span><span class="p">)</span>
<span class="n">original_image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1589467e449bf24af061b3e152ba1ed0ba8b442a276f0a0ad8f8f8eaadcc4631.png" src="../_images/1589467e449bf24af061b3e152ba1ed0ba8b442a276f0a0ad8f8f8eaadcc4631.png" />
</div>
</div>
<p>上記の画像を用いて姿勢情報を取得します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pose_image</span> <span class="o">=</span> <span class="n">openpose</span><span class="p">(</span><span class="n">original_image</span><span class="p">)</span>
<span class="n">pose_image</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d4501d20c5f09a48f34bcfd696c5f35abe565d020a2f583431712831b72b07ec.png" src="../_images/d4501d20c5f09a48f34bcfd696c5f35abe565d020a2f583431712831b72b07ec.png" />
</div>
</div>
</section>
<section id="id6">
<h3>複数の条件による ControlNet を動かす<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">StableDiffusionControlNetPipeline</span></code> のコンストラクタに ControlNet のリストを渡し、<code class="docutils literal notranslate"><span class="pre">__call__</span></code> に対応する条件のリスト (Canny エッジ画像・姿勢情報画像) を渡します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">controlnets</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ControlNetModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;lllyasviel/sd-controlnet-openpose&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">),</span>
    <span class="n">ControlNetModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;lllyasviel/sd-controlnet-canny&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_id</span><span class="p">,</span> <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnets</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">scheduer</span> <span class="o">=</span> <span class="n">UniPCMultistepScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

<span class="n">pipe</span><span class="o">.</span><span class="n">enable_xformers_memory_efficient_attention</span><span class="p">()</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">enable_model_cpu_offload</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "6b9b4281ad9543b18e218433d7e77d04"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[&quot;id2label&quot;]` will be overriden.
</pre></div>
</div>
</div>
</div>
<p>では姿勢情報とエッジ情報、更には生成画像に反映してほしくない内容を指定する negative prompt を渡して画像を生成させてみます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;a giant standing in a fantasy landscape, best quality&quot;</span>
<span class="n">negative_prompt</span> <span class="o">=</span> <span class="s2">&quot;monochrome, lowres, bad anatomy, worst quality, low quality&quot;</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">pose_image</span><span class="p">,</span> <span class="n">canny_image</span><span class="p">]</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">,</span>
    <span class="n">images</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
    <span class="n">controlnet_conditioning_scale</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
<span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">image_grid</span><span class="p">([</span><span class="n">image</span><span class="p">,</span> <span class="n">pose_image</span><span class="p">,</span> <span class="n">canny_image</span><span class="p">],</span> <span class="n">rows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "53eaa0dc23ab4a06b11b5b269a8c843a"}</script><img alt="../_images/f6990ed5bac7b6f245dbaff931ad57a3b35f4f81882334a687d0d4f35c5b7a52.png" src="../_images/f6990ed5bac7b6f245dbaff931ad57a3b35f4f81882334a687d0d4f35c5b7a52.png" />
</div>
</div>
<p>以上のようにして、複数の条件に忠実な画像生成が実現することを確認しました。本実習では複数の事例を通じて <code class="docutils literal notranslate"><span class="pre">StableDiffusionControlNetPipeline</span></code> の様々な面を探求し、diffusers を介した ControlNet が如何に簡単で直感的に動作させることができるかを示しました。しかしながら ControlNet がサポートするすべての条件付けをカバーしたわけではありません。詳細については以下のドキュメントページを確認してください:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-depth" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-depth</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-hed" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-hed</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-normal" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-normal</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-scribble" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-scribble</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-scribble" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-seg</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-openpose" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-openpose</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-mlsd" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-mlsd</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/lllyasviel/sd-controlnet-canny" rel="noreferrer" target="_blank">lllyasviel/sd-controlnet-canny</a></p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="section-07-22.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">前へ</p>
        <p class="prev-next-title">画像生成 AI 入門: Python による拡散モデルの理論と実践</p>
      </div>
    </a>
    <a class="right-next"
       href="section-07-24.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">次へ</p>
        <p class="prev-next-title">画像生成 AI 入門: Python による拡散モデルの理論と実践</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 目次
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-07-play-with-diffusion-model">Section 07. Play with Diffusion Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-23-controlnet">Lecture 23. ControlNet</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">セットアップ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu">GPU が使用できるか確認</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#python">利用する Python ライブラリをインストール</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlnet">ControlNet を扱うパイプラインを構築</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny">Canny エッジ画像の作成</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny-controlnet">Canny エッジ画像を用いた ControlNet による画像生成</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#controlnet-dreambooth">ControlNet と DreamBooth の組み合わせ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">姿勢情報を用いた ControlNet による画像生成</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">ControlNet による複数の条件を組み合わせた画像生成</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Canny エッジ画像の取得</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">姿勢情報の取得</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">複数の条件による ControlNet を動かす</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
著者 リサーチサイエンティスト 北田俊輔
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>