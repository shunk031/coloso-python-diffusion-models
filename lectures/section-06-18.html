

<!DOCTYPE html>


<html lang="ja" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ &#8212; ç”»åƒç”ŸæˆAIå…¥é–€: Pythonã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/section-06-18';</script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="ç´¢å¼•" href="../genindex.html" />
    <link rel="search" title="æ¤œç´¢" href="../search.html" />
    <link rel="next" title="ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ" href="section-07-19.html" />
    <link rel="prev" title="ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ" href="section-04-12.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ja"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    ç”»åƒç”Ÿæˆ AI å…¥é–€ï¼šPython ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-01-03.html">Play with Stable Diffusion!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-02-05.html">About Deep Learning (2)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-03-08.html">Score-based Generative Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-03-09.html">Denoising Diffusion Probabilistic Model (1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-03-10.html">Denoising Diffusion Probabilistic Model (2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-03-11.html">Beyond Conventional GANs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-04-12.html">About CLIP</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 6</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Components of Stable Diffusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section 7</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="section-07-19.html">Stable Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-20.html">Textual Inversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-21.html">DreamBooth</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-22.html">Attend-and-Excite</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-23.html">ControlNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-24.html">Prompt-to-Prompt</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-25.html">InstructPix2Pix</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-26.html">unCLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-27.html">Paint-by-example</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-28.html">LoRA</a></li>
<li class="toctree-l1"><a class="reference internal" href="section-07-29.html">Safe Latent Diffusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">å—è¬›è€…ç‰¹å…¸</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../materials/figures/README.html">é«˜è§£åƒåº¦å›³è¡¨</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/shunk031/coloso-python-diffusion-models/blob/main/lectures/section-06-18.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/shunk031/coloso-python-diffusion-models" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒª"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/shunk031/coloso-python-diffusion-models/issues/new?title=Issue%20on%20page%20%2Flectures/section-06-18.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="å•é¡Œã‚’å ±å‘Š"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="ã“ã®ãƒšãƒ¼ã‚¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lectures/section-06-18.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="PDFã«å°åˆ·"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="å…¨ç”»é¢ãƒ¢ãƒ¼ãƒ‰"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="æ¤œç´¢" aria-label="æ¤œç´¢" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> ç›®æ¬¡ </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-06-latent-diffusion-and-stable-diffusion">Section 06. Latent Diffusion and Stable Diffusion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-18-components-of-stable-diffusion">Lecture 18. Components of Stable Diffusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu">GPU ãŒä½¿ç”¨ã§ãã‚‹ã‹ç¢ºèª</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#python">åˆ©ç”¨ã™ã‚‹ Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-diffusion">Stable Diffusion ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vae-kingma-iclr-14">VAE <code class="docutils literal notranslate"><span class="pre">[Kingma+</span> <span class="pre">ICLR'14]</span></code> ã«ã¤ã„ã¦</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#u-net-ronneberger-miccai-15">U-Net <code class="docutils literal notranslate"><span class="pre">[Ronneberger+</span> <span class="pre">MICCAI'15]</span></code> ã«ã¤ã„ã¦</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-encoder-clip-text-encoder-radford-icml-21">Text Encoder (CLIP Text Encoder <code class="docutils literal notranslate"><span class="pre">[Radford+</span> <span class="pre">ICML'21]</span></code>) ã«ã¤ã„ã¦</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ldm">ãªãœ LDM ã¯é«˜é€Ÿã§åŠ¹ç‡çš„ãªã®ã‹ï¼Ÿ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Stable Diffusion ã®æ¨è«–</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusers-stable-diffusion">Diffusers ã‚’å…ƒã« Stable Diffusion ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é–¢ã‚ã‚Šåˆã„ã‚’ç¢ºèªã™ã‚‹</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ai-python">
<h1>ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ<a class="headerlink" href="#ai-python" title="Permalink to this heading">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/shunk031/coloso-python-diffusion-models/blob/main/lectures/section-06-18.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section id="section-06-latent-diffusion-and-stable-diffusion">
<h2>Section 06. Latent Diffusion and Stable Diffusion<a class="headerlink" href="#section-06-latent-diffusion-and-stable-diffusion" title="Permalink to this heading">#</a></h2>
<p>Latent Diffusion Model (LDM) ã¯ Stable Diffusion ã®å…ƒã¨ãªã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã€ã“ã‚Œã¾ã§ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦è¨ˆç®—é‡ãŒå°‘ãªãåºƒãä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚</p>
<p>æœ¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ LDM ã‚„ Stable Diffusion ã®æ¦‚è¦ã€ã¾ãŸã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã«å«ã¾ã‚Œã‚‹é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦å®Ÿéš›ã« diffusers ã‚’ä½¿ã£ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ã„ãã¾ã™ã€‚</p>
<section id="lecture-18-components-of-stable-diffusion">
<h3>Lecture 18. Components of Stable Diffusion<a class="headerlink" href="#lecture-18-components-of-stable-diffusion" title="Permalink to this heading">#</a></h3>
<p>ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é«˜ç”»è³ªãªç”»åƒã‚’ç”Ÿæˆå¯èƒ½ãª Stable Diffusion ã¯æœ€å…ˆç«¯ã®æŠ€è¡“ã‚’å«ã‚€è¤‡æ•°ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã€diffusers ã‚’ãƒ™ãƒ¼ã‚¹ã«ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å‹•ä½œåŸç†ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚</p>
</section>
</section>
<section id="id1">
<h2>ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<section id="gpu">
<h3>GPU ãŒä½¿ç”¨ã§ãã‚‹ã‹ç¢ºèª<a class="headerlink" href="#gpu" title="Permalink to this heading">#</a></h3>
<p>æœ¬ Colab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã« GPU ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚CPU ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã¨æ¯”ã¹ã¦ç”»åƒç”ŸæˆãŒã‚ˆã‚Šæ—©ããªã‚Šã¾ã™ã€‚ä»¥ä¸‹ã® <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> ã‚³ãƒãƒ³ãƒ‰ãŒå¤±æ•—ã™ã‚‹å ´åˆã¯å†åº¦è¬›ç¾©è³‡æ–™ã® <code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">ä½¿ç”¨è¨­å®š</span></code> ã®ã‚¹ãƒ©ã‚¤ãƒ‰èª¬æ˜ã‚„ Google Colab ã® <a class="reference external" href="https://research.google.com/colaboratory/faq.html#gpu-utilization">FAQ</a> ç­‰ã‚’å‚è€ƒã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒ—ãŒæ­£ã—ãå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sun Jun 25 02:15:50 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
</section>
<section id="python">
<h3>åˆ©ç”¨ã™ã‚‹ Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«<a class="headerlink" href="#python" title="Permalink to this heading">#</a></h3>
<p>diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å‹•ã‹ã™ä¸Šã§å¿…è¦ã¨ãªã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚‚è¿½åŠ ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/huggingface/transformers">transformers</a>: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦æ ¸ã¨ãªã‚‹ Transformer ãƒ¢ãƒ‡ãƒ«ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/accelerate">accelerate</a>: transformers ã¨é€£æºã—ã¦ã‚ˆã‚Šé«˜é€Ÿãªç”»åƒç”Ÿæˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install diffusers==0.16.1
!pip install transformers accelerate
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: diffusers==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (8.4.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (3.12.2)
Requirement already satisfied: huggingface-hub&gt;=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (0.15.1)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (6.7.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (1.22.4)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (2022.10.31)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1) (2.27.1)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (2023.6.0)
Requirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (4.65.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (6.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (4.6.3)
Requirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.13.2-&gt;diffusers==0.16.1) (23.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata-&gt;diffusers==0.16.1) (3.15.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers==0.16.1) (3.4)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)
Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)
Requirement already satisfied: safetensors&gt;=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)
Requirement already satisfied: torch&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (2023.6.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (4.6.3)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.6.0-&gt;accelerate) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.6.0-&gt;accelerate) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.6.0-&gt;accelerate) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.6.0-&gt;accelerate) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.6.0-&gt;accelerate) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.6.0-&gt;accelerate) (16.0.6)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=1.6.0-&gt;accelerate) (2.1.3)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=1.6.0-&gt;accelerate) (1.3.0)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="stable-diffusion">
<h2>Stable Diffusion ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦<a class="headerlink" href="#stable-diffusion" title="Permalink to this heading">#</a></h2>
<p>Stable Diffusion ã¯ã€<a class="reference external" href="https://arxiv.org/abs/2112.10752">High-Resolution Image Synthesis with Latent Diffusion Models</a> ã§ææ¡ˆã•ã‚ŒãŸ Latent Diffusion Model (LDM) ã¨ã„ã†ç‰¹æ®Šãªã‚¿ã‚¤ãƒ—ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚</p>
<p>LDM ã¯ã€å®Ÿéš›ã®ãƒ”ã‚¯ã‚»ãƒ«ç©ºé–“ã‚’ä½¿ç”¨ã™ã‚‹ä»£ã‚ã‚Šã«ã€ä½æ¬¡å…ƒã®æ½œåœ¨ç©ºé–“ä¸Šã§æ‹¡æ•£éç¨‹ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—ã®è¤‡é›‘ã•ã‚’è»½æ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚ŒãŒæ¨™æº–çš„ãªæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨ LDM ã®ä¸»ãªé•ã„ã§ã™ã€‚LDM ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã¯ç”»åƒã®æ½œåœ¨ï¼ˆåœ§ç¸®ï¼‰è¡¨ç¾ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚Œã¾ã™ã€‚</p>
<p>LDM ã¯ä»¥ä¸‹ã®3ã¤ã®ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™:</p>
<ul class="simple">
<li><p>Variational Auto-Encoder (VAE)</p></li>
<li><p>U-Net</p></li>
<li><p>Text encoder (CLIP text encoder)</p></li>
</ul>
<section id="vae-kingma-iclr-14">
<h3>VAE <a class="reference external" href="https://arxiv.org/abs/1312.6114"><code class="docutils literal notranslate"><span class="pre">[Kingma+</span> <span class="pre">ICLR'14]</span></code></a> ã«ã¤ã„ã¦<a class="headerlink" href="#vae-kingma-iclr-14" title="Permalink to this heading">#</a></h3>
<p>VAE ã«ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ (encoder) ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ (decoder) ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¯ã€ç”»åƒã‚’ä½æ¬¡å…ƒã®æ½œåœ¨è¡¨ç¾ã«å¤‰æ›ã—ã€U-Net ã®å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚ãƒ‡ã‚³ãƒ¼ãƒ€ã¯ã€é€†ã«æ½œåœ¨è¡¨ç¾ã‚’ç”»åƒã«å¤‰æ›ã—ã¾ã™ã€‚</p>
<p>LDM ã®å­¦ç¿’ã§ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§å°‘ã—ãšã¤ãƒã‚¤ã‚ºã‚’ä»˜ä¸ã—ã¦ã„ãæ‹¡æ•£éç¨‹ (forward diffusion process) ã®ãŸã‚ã«ã€ç”»åƒã®æ½œåœ¨è¡¨ç¾ (latent data) ã‚’å¾—ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚æ¨è«–ã§ã¯ã€é€†æ‹¡æ•£éç¨‹ (reverse diffusion process) ã§ç”Ÿæˆã•ã‚ŒãŸæ½œåœ¨ãƒ‡ãƒ¼ã‚¿ã‚’ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã§ç”»åƒã«æˆ»ã—ã¾ã™ã€‚å¾Œè¿°ã™ã‚‹ã‚ˆã†ã«ã€æ¨è«–æ™‚ã«å¿…è¦ãªã®ã¯VAEãƒ‡ã‚³ãƒ¼ãƒ€ã ã‘ã§ã™ã€‚</p>
</section>
<section id="u-net-ronneberger-miccai-15">
<h3>U-Net <a class="reference external" href="https://arxiv.org/abs/1505.04597"><code class="docutils literal notranslate"><span class="pre">[Ronneberger+</span> <span class="pre">MICCAI'15]</span></code></a> ã«ã¤ã„ã¦<a class="headerlink" href="#u-net-ronneberger-miccai-15" title="Permalink to this heading">#</a></h3>
<p>U-Netã¯ã€ResNet ãƒ–ãƒ­ãƒƒã‚¯ã§æ§‹æˆã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨ã¨ãƒ‡ã‚³ãƒ¼ãƒ€éƒ¨ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ç”»åƒè¡¨ç¾ã‚’ä½è§£åƒåº¦ç”»åƒè¡¨ç¾ã«åœ§ç¸® (encode) ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã¯ä½è§£åƒåº¦ç”»åƒè¡¨ç¾ã‚’ãƒã‚¤ã‚ºã®å°‘ãªã„å…ƒã®é«˜è§£åƒåº¦ç”»åƒè¡¨ç¾ã«å¾©å· (decode) ã—ã¾ã™ã€‚ã‚ˆã‚Šå…·ä½“çš„ã« U-Net ã¯ãƒã‚¤ã‚ºç”»åƒã‹ã‚‰ãƒã‚¤ã‚ºéƒ¨åˆ†ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ã“ã‚Œã¯æœ€çµ‚çš„ã«ãƒã‚¤ã‚ºç”»åƒã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹éš›ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚</p>
<p>U-NetãŒãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­ã«é‡è¦ãªæƒ…å ±ã‚’å¤±ã†ã®ã‚’é˜²ããŸã‚ã€é€šå¸¸ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ResNet ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ã®ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ResNet ã®é–“ã«ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã®æ¥ç¶š (skip connection, residual connection ãªã©ã¨å‘¼ã°ã‚Œã‚‹) ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚ã•ã‚‰ã«ã€Stable Diffusion ã® U-Net ã¯ã€cross attention å±¤ã‚’ä»‹ã—ã¦ã€CLIP text encoder ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ã®åŸºã¥ãæ¡ä»¶ä»˜ã‘ãŒå¯èƒ½ã§ã™ã€‚Cross attention å±¤ã¯ã€U-Net ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨ã¨ãƒ‡ã‚³ãƒ¼ãƒ€éƒ¨ã®ä¸¡æ–¹ã«ã€é€šå¸¸ ResNet ãƒ–ãƒ­ãƒƒã‚¯ã®é–“ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚</p>
</section>
<section id="text-encoder-clip-text-encoder-radford-icml-21">
<h3>Text Encoder (CLIP Text Encoder <a class="reference external" href="https://arxiv.org/abs/2103.00020"><code class="docutils literal notranslate"><span class="pre">[Radford+</span> <span class="pre">ICML'21]</span></code></a>) ã«ã¤ã„ã¦<a class="headerlink" href="#text-encoder-clip-text-encoder-radford-icml-21" title="Permalink to this heading">#</a></h3>
<p>ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€ä¾‹ãˆã° <code class="docutils literal notranslate"><span class="pre">&quot;An</span> <span class="pre">astronout</span> <span class="pre">riding</span> <span class="pre">a</span> <span class="pre">horse&quot;</span></code> ã®ã‚ˆã†ãªå…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã€U-Net ãŒç†è§£ã§ãã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å½¹å‰²ã‚’æ‹…ã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯é€šå¸¸ã€å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’æ½œåœ¨çš„ãªãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ã®åˆ—ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ã®ã¿ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚</p>
<p>Stable Diffusion ã¯ Imagen <a class="reference external" href="https://arxiv.org/abs/2205.11487">[Saharia+ NeurIPS'22]</a> ã‚’å‚è€ƒã«ã—ã¦ãŠã‚Šã€å­¦ç¿’ä¸­ã« CLIP text encoder ã‚’å­¦ç¿’ã›ãšã€å˜ã«äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚</p>
</section>
<section id="ldm">
<h3>ãªãœ LDM ã¯é«˜é€Ÿã§åŠ¹ç‡çš„ãªã®ã‹ï¼Ÿ<a class="headerlink" href="#ldm" title="Permalink to this heading">#</a></h3>
<p>LDM ã® U-Net ã¯ä½æ¬¡å…ƒç©ºé–“ã§å‹•ä½œã™ã‚‹ãŸã‚ã€ãƒ”ã‚¯ã‚»ãƒ«ç©ºé–“ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ãƒ¡ãƒ¢ãƒªã‚„è¨ˆç®—é‡ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€Stable Diffusionã§ä½¿ç”¨ã•ã‚Œã‚‹ Auto-Encoder ã¯ã€ç¸®å°ç‡ãŒ8ã§ã‚ã‚Šã€ã“ã‚Œã¯ã€å½¢çŠ¶ãŒ <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">512,</span> <span class="pre">512)</span></code> ã®ç”»åƒãŒæ½œåœ¨ç©ºé–“ã§ã¯ <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">64,</span> <span class="pre">64)</span></code> ã¨ãªã‚Šã¾ã™ã€‚ã“ã‚Œã¯ LDM ã®ã‚ˆã†ã«å…¥åŠ›ã¨ã—ã¦æ½œåœ¨ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªãç”»åƒã¨ã—ã¦æ‰±ã£ã¦ã—ã¾ã†ã¨<code class="docutils literal notranslate"><span class="pre">8</span> <span class="pre">âœ•</span> <span class="pre">8</span> <span class="pre">=</span> <span class="pre">64</span></code> å€ã®ãƒ¡ãƒ¢ãƒªã‚’å¿…è¦ã¨ã™ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¦ã„ã¾ã™ã€‚</p>
<p>ã“ã‚ŒãŒã€16 GB GPU RAM ã‚’æœ‰ã™ã‚‹ Colab ã§ã‚‚ã€<code class="docutils literal notranslate"><span class="pre">512</span> <span class="pre">âœ•</span> <span class="pre">512</span></code> ã®ç”»åƒã‚’é«˜é€Ÿã«ç”Ÿæˆã§ãã‚‹ç†ç”±ã§ã™ ğŸ¤—</p>
</section>
<section id="id2">
<h3>Stable Diffusion ã®æ¨è«–<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>ãã‚Œã§ã¯ã€æ¨è«–æ™‚ã®ãƒ¢ãƒ‡ãƒ«ã®å‹•ãã‚’ã€è«–ç†çš„ãªæµã‚Œã§è©³ã—ãè¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚</p>
<p>Stable Diffusion ã¯ã€æ½œåœ¨çš„ãª seed ã¨ text prompt ã®ä¸¡æ–¹ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚æ½œåœ¨çš„ãª seed ã‚’å…ƒã«ã€ãƒ©ãƒ³ãƒ€ãƒ ãªãƒã‚¤ã‚ºã‚’å…ƒã«ã—ãŸ <code class="docutils literal notranslate"><span class="pre">64</span> <span class="pre">âœ•</span> <span class="pre">64</span></code> ã‚µã‚¤ã‚ºã®ãƒã‚¤ã‚ºç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚
ä¸€æ–¹ã€text prompt ã¯ CLIP ã® text encoder ã«ã‚ˆã£ã¦ã€<code class="docutils literal notranslate"><span class="pre">77</span> <span class="pre">âœ•</span> <span class="pre">768</span></code> ã‚µã‚¤ã‚ºã®ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚</p>
<p>æ¬¡ã«ã€U-Net ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¡ä»¶ã¨ã—ã¦ã€ãƒã‚¤ã‚ºç”»åƒã‹ã‚‰ç¹°ã‚Šè¿”ã—ãƒã‚¤ã‚ºé™¤å»ã—ã¾ã™ã€‚U-Net ã®å‡ºåŠ›ã¯ç”ŸæˆãŒæœŸå¾…ã•ã‚Œã‚‹ç¶ºéº—ãªç”»åƒã¨ç¾åœ¨ã®ãƒã‚¤ã‚ºç”»åƒã¨ã®å·®åˆ†ã§ã™ã€‚ã“ã®å‡ºåŠ›ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã£ã¦ãƒã‚¤ã‚ºé™¤å»ã•ã‚ŒãŸæ½œåœ¨è¡¨ç¾ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ã“ã®è¨ˆç®—ã«ã¯å¤šãã®ç•°ãªã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€ãã‚Œãã‚Œã«é•·æ‰€ã¨çŸ­æ‰€ãŒã‚ã‚Šã¾ã™ã€‚Stable Diffusionã§ã¯ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py">PNDM ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼</a></p>
<ul>
<li><p>ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py">K-LMS ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼</a></p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_heun_discrete.py">Heun Discrete ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼</a></p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_dpmsolver_multistep.py">DPM Solver Multistep ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼</a></p>
<ul>
<li><p>ã“ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã¯ã€ã‚ˆã‚Šå°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—ã§å„ªã‚ŒãŸå“è³ªã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®50ã§ã¯ãªãã€25ã§è©¦ã™ã“ã¨ãŒã§ãã¾ã™ ğŸ¤—</p></li>
</ul>
</li>
</ul>
<p>ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ©Ÿèƒ½ã«é–¢ã™ã‚‹ç†è«–ã¯ã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ç¯„å›²å¤–ã§ã™ãŒã€è¦ã™ã‚‹ã«ã€ä»¥å‰ã®ãƒã‚¤ã‚ºè¡¨ç¾ã¨äºˆæ¸¬ãƒã‚¤ã‚ºã®æ®‹å·®ã‹ã‚‰ã€äºˆæ¸¬ãƒã‚¤ã‚ºé™¤å»ç”»åƒè¡¨ç¾ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã‚’è¦šãˆã¦ãŠãã¨ã‚ˆã„ã§ã—ã‚‡ã†ã€‚è©³ã—ãã¯ã€ã€Œ<a class="reference external" href="https://arxiv.org/abs/2206.00364">æ‹¡æ•£ã«åŸºã¥ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆç©ºé–“ã®è§£æ˜ - Elucidating the Design Space of Diffusion-Based Generative Models</a>ã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
<p>ã“ã®ãƒã‚¤ã‚ºé™¤å»å‡¦ç†ã‚’ç´„ 50 å›ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€ã‚ˆã‚Šè‰¯ã„æ½œåœ¨è¡¨ç¾ã‚’æ®µéšçš„ã«å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ½œåœ¨è¡¨ç¾ãŒå®Œæˆã™ã‚‹ã¨ã€VAE ã®ãƒ‡ã‚³ãƒ¼ãƒ€éƒ¨ã«ã‚ˆã£ã¦å¾©å·ã•ã‚Œã€ç”Ÿæˆç”»åƒã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
</section>
</section>
<section id="diffusers-stable-diffusion">
<h2>Diffusers ã‚’å…ƒã« Stable Diffusion ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é–¢ã‚ã‚Šåˆã„ã‚’ç¢ºèªã™ã‚‹<a class="headerlink" href="#diffusers-stable-diffusion" title="Permalink to this heading">#</a></h2>
<p>ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ <a class="reference external" href="https://arxiv.org/abs/2206.00364">Karras+ NeurIPS'22</a> ã® <a class="reference external" href="https://huggingface.co/docs/diffusers/api/schedulers/lms_discrete">K-LMS ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼</a> ã¨å‘¼ã°ã‚Œã‚‹ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚‚ã®ã¨ã¯å°‘ã—ç•°ãªã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’åˆ©ç”¨ã—ã¦ Stable Diffusion ã‚’ä½¿ã†æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚</p>
<p>ã¾ãšã€é–¢ä¿‚ã™ã‚‹å€‹ã€…ã®ãƒ¢ãƒ‡ãƒ«ã‚„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã™ã€‚GPU ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«æŒ‡å®šã—ã€èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ <code class="docutils literal notranslate"><span class="pre">runwayml/stable-diffusion-v1-5</span></code> ã‚’æŒ‡å®šã—ã¾ã—ãŸã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch_device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="n">sd_model_id</span> <span class="o">=</span> <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span>
<span class="n">clip_model_id</span> <span class="o">=</span> <span class="s2">&quot;openai/clip-vit-large-patch14&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>å­¦ç¿’æ¸ˆã¿ Stable Diffusion ã«ã¯ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€åãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã§ãã‚Œãã‚Œå­¦ç¿’æ¸ˆã¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒæ ¼ç´ã•ã‚Œã¦ã„ã¾ã™:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">text_encoder</span></code>: Stable Diffusion ã¯ CLIP ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€ä»–ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã¯BERT ãªã©ä»–ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tokenizer</span></code>: <code class="docutils literal notranslate"><span class="pre">text_encoder</span></code> ãƒ¢ãƒ‡ãƒ«ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¨ä¸€è‡´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scheduler</span></code>: å­¦ç¿’ä¸­ã«ç”»åƒã«ãƒã‚¤ã‚ºã‚’å¾ã€…ã«è¿½åŠ ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unet</span></code>: å…¥åŠ›ã®æ½œåœ¨çš„ãªè¡¨ç¾ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vae</span></code>: æ½œåœ¨è¡¨ç¾ã‚’å®Ÿç”»åƒã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ auto-encoder ãƒ¢ãƒ‡ãƒ«ã§ã™</p></li>
</ul>
<p>å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ <code class="docutils literal notranslate"><span class="pre">from_pretrained</span></code> é–¢æ•°ã® <code class="docutils literal notranslate"><span class="pre">subfolder</span></code> å¼•æ•°ã‚’ç”¨ã„ã¦ã€ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã§ã€å¯¾è±¡ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">CLIPTextModel</span><span class="p">,</span> <span class="n">CLIPTokenizer</span>
<span class="kn">from</span> <span class="nn">diffusers</span> <span class="kn">import</span> <span class="n">AutoencoderKL</span><span class="p">,</span> <span class="n">UNet2DConditionModel</span><span class="p">,</span> <span class="n">PNDMScheduler</span>

<span class="c1"># VAE ã¨ U-Net ã¯ Stable Diffusion ã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">AutoencoderKL</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">sd_model_id</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;vae&quot;</span><span class="p">)</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">UNet2DConditionModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">sd_model_id</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;unet&quot;</span><span class="p">)</span>

<span class="c1"># CLIP ã¯ openai/clip-vit-large-patch14 ã‹ã‚‰èª­ã¿è¾¼ã‚€</span>
<span class="c1"># Stable Diffusion å­¦ç¿’æ™‚ã«ã¯ CLIP ã¯ freeze ã•ã‚Œã¦ã„ã‚‹ãŸã‚</span>
<span class="c1"># ã‚‚ã¨ã‚‚ã¨ã®é‡ã¿ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã§ã‚‚å‹•ä½œãŒå¯èƒ½</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">clip_model_id</span><span class="p">)</span>
<span class="n">text_encoder</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">clip_model_id</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "f5fca0de9a284a71ad26f196d8c44a6f"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "bd0dd463d9e8420eb1fc5bc8a03a2cfe"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "3a8bed3d328e4c45b7cd9db6c7319196"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "a07c2a3d8f274d46b858b29a588053fe"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "a9fb19128e6b481c9d101a8db1193dfa"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "38f6d933b63d4f3fbe304c8ff2dbbdbc"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "c5428cb17a184b6a9fba28b64124cc98"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "38474b25b1e041f29744775c829db699"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0692ae1ea1794329aad96e17c03c08ca"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2a11bcbde6034f998e4f4dabb0577579"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: [&#39;vision_model.encoder.layers.21.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.3.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.11.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.1.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.19.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.17.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.12.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.8.mlp.fc2.weight&#39;, &#39;vision_model.embeddings.position_ids&#39;, &#39;vision_model.encoder.layers.12.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.15.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.15.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.23.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.13.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.5.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.0.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.2.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.8.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.11.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.12.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.16.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.19.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.0.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.22.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.1.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.9.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.10.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.22.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.9.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.15.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.9.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.1.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.6.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.9.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.4.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.11.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.0.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.9.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.15.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.7.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.12.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.20.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.12.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.17.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.19.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.23.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.16.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.10.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.5.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.21.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.15.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.23.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.23.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.5.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.2.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.6.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.7.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.20.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.7.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.5.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.12.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.2.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.7.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.18.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.0.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.11.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.9.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.16.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.9.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.16.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.13.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.6.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.16.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.6.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.10.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.14.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.0.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.0.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.15.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.12.self_attn.k_proj.weight&#39;, &#39;visual_projection.weight&#39;, &#39;vision_model.encoder.layers.13.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.5.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.4.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.12.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.4.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.12.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.15.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.2.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.8.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.14.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.1.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.3.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.3.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.14.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.1.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.21.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.14.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.22.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.10.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.2.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.3.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.6.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.1.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.15.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.23.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.17.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.20.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.0.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.4.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.7.self_attn.out_proj.weight&#39;, &#39;vision_model.post_layernorm.weight&#39;, &#39;vision_model.encoder.layers.19.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.21.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.13.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.14.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.16.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.9.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.10.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.5.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.12.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.18.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.1.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.10.layer_norm1.bias&#39;, &#39;vision_model.pre_layrnorm.bias&#39;, &#39;vision_model.encoder.layers.7.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.5.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.2.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.22.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.1.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.22.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.0.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.21.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.22.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.20.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.7.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.14.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.22.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.4.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.7.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.13.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.7.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.9.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.20.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.22.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.23.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.9.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.20.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.10.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.17.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.21.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.13.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.17.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.3.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.13.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.21.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.10.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.6.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.16.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.10.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.2.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.23.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.19.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.8.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.8.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.21.layer_norm2.weight&#39;, &#39;vision_model.embeddings.position_embedding.weight&#39;, &#39;vision_model.encoder.layers.5.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.19.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.14.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.12.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.6.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.14.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.1.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.2.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.5.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.17.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.19.self_attn.k_proj.weight&#39;, &#39;vision_model.embeddings.patch_embedding.weight&#39;, &#39;vision_model.encoder.layers.2.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.5.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.20.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.18.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.13.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.1.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.23.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.4.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.17.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.2.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.7.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.13.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.17.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.18.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.4.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.1.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.20.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.18.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.7.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.6.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.8.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.19.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.2.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.17.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.16.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.15.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.2.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.15.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.0.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.14.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.3.self_attn.v_proj.bias&#39;, &#39;vision_model.pre_layrnorm.weight&#39;, &#39;vision_model.encoder.layers.21.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.2.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.11.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.5.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.16.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.11.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.9.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.15.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.20.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.0.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.3.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.6.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.14.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.11.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.19.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.18.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.4.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.0.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.21.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.4.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.18.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.22.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.7.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.18.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.14.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.13.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.10.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.11.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.12.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.8.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.6.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.4.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.3.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.9.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.22.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.11.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.6.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.8.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.16.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.13.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.18.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.19.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.16.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.16.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.2.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.20.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.11.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.3.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.17.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.4.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.18.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.7.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.9.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.13.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.5.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.6.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.22.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.14.self_attn.v_proj.weight&#39;, &#39;vision_model.embeddings.class_embedding&#39;, &#39;vision_model.encoder.layers.17.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.19.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.18.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.20.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.3.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.3.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.13.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.21.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.23.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.3.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.15.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.13.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.14.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.19.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.19.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.8.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.4.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.18.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.12.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.20.self_attn.k_proj.bias&#39;, &#39;vision_model.post_layernorm.bias&#39;, &#39;vision_model.encoder.layers.10.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.15.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.9.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.8.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.1.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.20.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.17.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.16.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.10.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.18.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.9.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.14.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.16.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.18.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.4.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.3.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.15.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.8.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.0.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.20.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.10.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.22.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.23.layer_norm2.bias&#39;, &#39;text_projection.weight&#39;, &#39;vision_model.encoder.layers.8.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.14.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.11.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.17.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.2.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.12.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.17.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.21.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.12.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.6.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.6.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.10.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.5.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.22.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.6.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.14.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.22.self_attn.out_proj.weight&#39;, &#39;vision_model.encoder.layers.20.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.3.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.17.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.22.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.7.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.21.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.11.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.5.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.8.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.11.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.13.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.8.layer_norm1.weight&#39;, &#39;logit_scale&#39;, &#39;vision_model.encoder.layers.4.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.5.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.23.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.18.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.0.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.10.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.19.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.18.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.1.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.23.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.23.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.1.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.12.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.2.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.7.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.8.self_attn.k_proj.bias&#39;, &#39;vision_model.encoder.layers.3.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.11.mlp.fc2.bias&#39;, &#39;vision_model.encoder.layers.10.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.21.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.22.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.21.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.23.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.8.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.0.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.5.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.19.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.16.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.15.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.0.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.7.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.1.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.4.layer_norm1.weight&#39;, &#39;vision_model.encoder.layers.0.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.21.mlp.fc2.weight&#39;, &#39;vision_model.encoder.layers.3.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.13.self_attn.v_proj.bias&#39;, &#39;vision_model.encoder.layers.11.mlp.fc1.weight&#39;, &#39;vision_model.encoder.layers.17.mlp.fc1.bias&#39;, &#39;vision_model.encoder.layers.23.layer_norm2.weight&#39;, &#39;vision_model.encoder.layers.16.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.15.self_attn.q_proj.weight&#39;, &#39;vision_model.encoder.layers.11.self_attn.k_proj.weight&#39;, &#39;vision_model.encoder.layers.23.self_attn.out_proj.bias&#39;, &#39;vision_model.encoder.layers.9.layer_norm1.bias&#39;, &#39;vision_model.encoder.layers.1.layer_norm2.bias&#39;, &#39;vision_model.encoder.layers.6.self_attn.v_proj.weight&#39;, &#39;vision_model.encoder.layers.20.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.4.self_attn.q_proj.bias&#39;, &#39;vision_model.encoder.layers.19.layer_norm1.weight&#39;]
- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</pre></div>
</div>
</div>
</div>
<p>ä»Šåº¦ã¯ã€ã‚ã‚‰ã‹ã˜ã‚ç”¨æ„ã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã‚€ã®ã§ã¯ãªãã€K-LMSã€€ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ã†ã“ã¨ã«ã—ã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">diffusers</span> <span class="kn">import</span> <span class="n">LMSDiscreteScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LMSDiscreteScheduler</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">sd_model_id</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;scheduler&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "9f306d76cab0423ebebb8b37c721a0be"}</script></div>
</div>
<p>æ¬¡ã«ã€èª­ã¿è¾¼ã‚“ã ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’GPUã«ç§»å‹•ã•ã›ã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vae</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_device</span><span class="p">)</span>
<span class="n">text_encoder</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_device</span><span class="p">)</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">unet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>ç”»åƒç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;a photograph of an astronaut riding a horse&quot;</span>

<span class="n">height</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># ç”Ÿæˆç”»åƒã®é«˜ã•</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># ç”Ÿæˆç”»åƒã®å¹…</span>

<span class="n">num_inference_steps</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># ãƒã‚¤ã‚ºé™¤å»ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°; ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨</span>

<span class="n">guidance_scale</span> <span class="o">=</span> <span class="mf">7.5</span> <span class="c1"># classifier-free guidance ã® guidance scale</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>   <span class="c1"># seed ã‚’ç”Ÿæˆã™ã‚‹ generator</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">guidance_scale</span></code> ã¯ã€<a class="reference external" href="https://arxiv.org/abs/2205.11487">Imagen ã®è«–æ–‡</a> ã®å¼ (2) ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹é‡ã¿ <code class="docutils literal notranslate"><span class="pre">w</span></code> ã«é¡ä¼¼ã—ã¦å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚<code class="docutils literal notranslate"><span class="pre">guidance_scale</span> <span class="pre">==</span> <span class="pre">1</span></code> ã¯ã€åˆ†é¡å™¨ä¸ä½¿ç”¨èª˜å° (classifier-free guidance) ã‚’è¡Œã†ã“ã¨ã«ç›¸å½“ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€å‰å›ã¨åŒæ§˜ã« 7.5 ã«è¨­å®šã—ã¦ã„ã¾ã™ã€‚</p>
<p>ã¾ãšã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ã‚’ <code class="docutils literal notranslate"><span class="pre">text_embeddings</span></code> (embeddings: åŸ‹ã‚è¾¼ã¿; ã‚ã‚‹ä½æ¬¡å…ƒç©ºé–“ã¸ã®å†™åƒã‚’ &quot;åŸ‹ã‚è¾¼ã‚€&quot; ã¨èª­ã‚“ã ã‚Šã™ã‚‹ãŸã‚ã«ã€åŸ‹ã‚è¾¼ã¿ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™) ã¨ã—ã¦å–å¾—ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã¯ U-Net ãƒ¢ãƒ‡ãƒ«ã®æ¡ä»¶ä»˜ã‘ã«ä½¿ã‚ã‚Œã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">(</span><span class="n">text_input</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_device</span><span class="p">))</span>
    <span class="n">text_embeddings</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>

<span class="nb">print</span><span class="p">(</span><span class="n">text_embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 77, 768])
</pre></div>
</div>
</div>
</div>
<p>Classifier-free guidance ã®ãŸã‚ã®æ¡ä»¶ãªã—ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ã—ã¾ã™ã€‚å®Ÿéš›ã¯ padding token (ç©ºãƒ†ã‚­ã‚¹ãƒˆ) ã«å¯¾ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®ã¿ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã€æ¡ä»¶ä»˜ã <code class="docutils literal notranslate"><span class="pre">text_embeddings</span></code> (<code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">seq_length</span></code>) ã¨åŒã˜ã‚µã‚¤ã‚ºã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_length</span> <span class="o">=</span> <span class="n">text_input</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">uncond_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
<span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_device</span><span class="p">))</span>
    <span class="n">uncond_embeddings</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>

<span class="nb">print</span><span class="p">(</span><span class="n">uncond_embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 77, 768])
</pre></div>
</div>
</div>
</div>
<p>Classifier-free guidance ã®ãŸã‚ã«ã€2å› <code class="docutils literal notranslate"><span class="pre">text_encoder</span></code> ã«å…¥åŠ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚1 ã¤ã¯æ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ« (<code class="docutils literal notranslate"><span class="pre">text_embeddings</span></code>)ã€ã‚‚ã† 1 ã¤ã¯æ¡ä»¶ãªã—ãƒ™ã‚¯ãƒˆãƒ« (<code class="docutils literal notranslate"><span class="pre">uncond_embeddings</span></code>) ã§ã™ã€‚å®Ÿéš›ã¯ 2 å›ã®å…¥åŠ›ã‚’é¿ã‘ã‚‹ãŸã‚ã«ä¸¡è€…ã‚’ 1 ã¤ã®ãƒãƒƒãƒã«é€£çµã—ã¦å…¥åŠ›ã™ã‚‹æ–¹æ³•ãŒã¨ã‚‰ã‚Œã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">uncond_embeddings</span><span class="p">,</span> <span class="n">text_embeddings</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">text_embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 77, 768])
</pre></div>
</div>
</div>
</div>
<p>ç”»åƒç”Ÿæˆã®ãŸã‚ã«ã€åˆæœŸã®çŠ¶æ…‹ã¨ãªã‚‹ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã‚’ç”Ÿæˆã—ã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">latents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
  <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">height</span> <span class="o">//</span> <span class="mi">8</span><span class="p">,</span> <span class="n">width</span> <span class="o">//</span> <span class="mi">8</span><span class="p">),</span>
  <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_device</span><span class="p">)</span>

<span class="n">latents</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 4, 64, 64])
</pre></div>
</div>
</div>
</div>
<p>ã‚µã‚¤ã‚ºãŒ <code class="docutils literal notranslate"><span class="pre">64</span> <span class="pre">x</span> <span class="pre">64</span></code> ã®æ½œåœ¨ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã“ã®æ½œåœ¨ãƒ‡ãƒ¼ã‚¿ (åˆæœŸã¯ç´”ç²‹ãªãƒã‚¤ã‚º) ã‚’ã€é€†æ‹¡æ•£éç¨‹ã¨ VAE ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’çµŒã¦ <code class="docutils literal notranslate"><span class="pre">512</span> <span class="pre">x</span> <span class="pre">512</span></code> ã®ç”»åƒã¨ã—ã¦å¤‰æ›ã—ã¦ã„ãã¾ã™ã€‚</p>
<p>æ¬¡ã«ã€é¸æŠã—ãŸ <code class="docutils literal notranslate"><span class="pre">num_inference_steps</span></code> ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒã‚¤ã‚ºé™¤å»å‡¦ç†ä¸­ã«ä½¿ç”¨ã•ã‚Œã‚‹ Ïƒ ã¨æ­£ç¢ºãªã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>K-LMS ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã¯ã€æ½œåœ¨ãƒ‡ãƒ¼ã‚¿ã« Ïƒ ã‚’æ›ã‘ã‚‹åˆã‚ã›ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã—ã¦ãŠãã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">*</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">init_noise_sigma</span>
</pre></div>
</div>
</div>
</div>
<p>ãƒã‚¤ã‚ºé™¤å»ã®ãƒ«ãƒ¼ãƒ—ã‚’è¨ˆç®—ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦æ®µéšçš„ã«ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã¦ã„ãã¾ã—ã‚‡ã†ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">autocast</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span><span class="p">):</span>

    <span class="c1"># Classifier-free guidance ã§ 2 å› ã®ãƒ¢ãƒ‡ãƒ« forward è¨ˆç®—ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€æ½œåœ¨ãƒ‡ãƒ¼ã‚¿ã‚’ 2 ã¤ã«ã«ã—ã¦ãƒãƒƒãƒåŒ–ã—ã¾ã™</span>
    <span class="n">latent_model_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">latent_model_input</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">scale_model_input</span><span class="p">(</span><span class="n">latent_model_input</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

    <span class="c1"># U-Net ã‚’å…ƒã«ãƒã‚¤ã‚ºæ®‹å·®ã‚’äºˆæ¸¬ã—ã¾ã™</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">unet</span><span class="p">(</span><span class="n">latent_model_input</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">text_embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span>

    <span class="c1"># Classifier-free guidance ã‚’é©ç”¨ã—ã¾ã™</span>
    <span class="c1"># - è¨ˆç®—ã•ã‚ŒãŸãƒã‚¤ã‚ºæ®‹å·®ã«å¯¾ã—ã¦ã€ç„¡æ¡ä»¶ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ããƒ™ã‚¯ãƒˆãƒ«ã«åˆ†å‰²</span>
    <span class="c1"># - åˆ†å‰²ã•ã‚ŒãŸãã‚Œãã‚Œã‚’ç”¨ã„ã¦ classifier-free guidance ã‚’è¨ˆç®—</span>
    <span class="n">noise_pred_uncond</span><span class="p">,</span> <span class="n">noise_pred_text</span> <span class="o">=</span> <span class="n">noise_pred</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">noise_pred_uncond</span> <span class="o">+</span> <span class="n">guidance_scale</span> <span class="o">*</span> <span class="p">(</span><span class="n">noise_pred_text</span> <span class="o">-</span> <span class="n">noise_pred_uncond</span><span class="p">)</span>

    <span class="c1"># ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ— x_t ã‹ã‚‰å‰ã®ã‚¹ãƒ†ãƒƒãƒ— x_{t-1} ã‚’äºˆæ¸¬</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">noise_pred</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span><span class="o">.</span><span class="n">prev_sample</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "acf69148f79742feaaecf9c8455c03ff"}</script></div>
</div>
<p>ç”Ÿæˆã•ã‚ŒãŸæ½œåœ¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”»åƒã«æˆ»ã™ãŸã‚ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã« <code class="docutils literal notranslate"><span class="pre">vae</span></code> ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># é©åˆ‡ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è¡Œã£ãŸå¾Œã«ã€VAE ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’è¡Œã†</span>
<span class="n">latents</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">0.18215</span> <span class="o">*</span> <span class="n">latents</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">latents</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span>
</pre></div>
</div>
</div>
</div>
<p>æœ€å¾Œã«ã€ç”»åƒã‚’ç°¡å˜ã«è¡¨ç¤ºã—ãŸã‚Šä¿å­˜ã—ãŸã‚Šã§ãã‚‹ã‚ˆã†ã«ã€PIL å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>
<span class="n">pil_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>
<span class="n">pil_images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/93d40d96df9999ff0cf380a10d223542c465636d970bfd55b815592d683d3caa.png" src="../_images/93d40d96df9999ff0cf380a10d223542c465636d970bfd55b815592d683d3caa.png" />
</div>
</div>
<p>ä»¥ä¸Šã®ã‚ˆã†ã«ã—ã¦ Stable Diffusion ã‚’æ§‹æˆã™ã‚‹å„è¦ç´ ã‚’ä½¿ç”¨ã—ã¦è‡ªèº«ã®å¥½ããªã‚ˆã†ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹æ‰‹é †ã‚’ä¸€é€šã‚Šä½“é¨“ã—ã¦ã„ãŸã ãã¾ã—ãŸã€‚</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="section-04-12.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">å‰ã¸</p>
        <p class="prev-next-title">ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ</p>
      </div>
    </a>
    <a class="right-next"
       href="section-07-19.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">æ¬¡ã¸</p>
        <p class="prev-next-title">ç”»åƒç”Ÿæˆ AI å…¥é–€: Python ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è«–ã¨å®Ÿè·µ</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> ç›®æ¬¡
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-06-latent-diffusion-and-stable-diffusion">Section 06. Latent Diffusion and Stable Diffusion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-18-components-of-stable-diffusion">Lecture 18. Components of Stable Diffusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu">GPU ãŒä½¿ç”¨ã§ãã‚‹ã‹ç¢ºèª</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#python">åˆ©ç”¨ã™ã‚‹ Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stable-diffusion">Stable Diffusion ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vae-kingma-iclr-14">VAE <code class="docutils literal notranslate"><span class="pre">[Kingma+</span> <span class="pre">ICLR'14]</span></code> ã«ã¤ã„ã¦</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#u-net-ronneberger-miccai-15">U-Net <code class="docutils literal notranslate"><span class="pre">[Ronneberger+</span> <span class="pre">MICCAI'15]</span></code> ã«ã¤ã„ã¦</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-encoder-clip-text-encoder-radford-icml-21">Text Encoder (CLIP Text Encoder <code class="docutils literal notranslate"><span class="pre">[Radford+</span> <span class="pre">ICML'21]</span></code>) ã«ã¤ã„ã¦</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ldm">ãªãœ LDM ã¯é«˜é€Ÿã§åŠ¹ç‡çš„ãªã®ã‹ï¼Ÿ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Stable Diffusion ã®æ¨è«–</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusers-stable-diffusion">Diffusers ã‚’å…ƒã« Stable Diffusion ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é–¢ã‚ã‚Šåˆã„ã‚’ç¢ºèªã™ã‚‹</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
è‘—è€… ãƒªã‚µãƒ¼ãƒã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ åŒ—ç”°ä¿Šè¼”
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>